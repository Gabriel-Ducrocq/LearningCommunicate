{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from bptt import BPTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PhysicalNet: \n",
    "    \n",
    "    def __init__(self, layer_sizes, input_size, first_input, output_size, keep_prob = 0.9, stddev = 0.001):\n",
    "        self.nb_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.first_input = first_input\n",
    "        self.stddev = stddev\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.intermediate_outputs = [self.first_input]\n",
    "        \n",
    "        self.init_weights()\n",
    "        self.init_biases()\n",
    "        self.define_inter_outputs()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for i in range(self.nb_layers):\n",
    "            if i == 0:\n",
    "                W = tf.Variable(tf.random_normal([self.layer_sizes[i], self.input_size], stddev = self.stddev))\n",
    "            elif i != (self.nb_layers - 1):\n",
    "                W = tf.Variable(tf.random_normal([self.layer_sizes[(i+1)], self.layer_sizes[i]], stddev = self.stddev))\n",
    "            else:\n",
    "                W = tf.Variable(tf.random_normal([self.output_size, self.layer_sizes[i]], stddev = self.stddev))\n",
    "                \n",
    "            self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        for i in range(self.nb_layers):\n",
    "            B = tf.Variable(tf.random_normal([self.layer_sizes[i], 1], stddev = self.stddev))\n",
    "            self.Biases.append(B)\n",
    "            \n",
    "    def define_inter_outputs(self): ## ADD THE DROPOUTS !!!\n",
    "        for i in range(self.nb_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            x = self.intermediate_outputs[i]\n",
    "            if i != (self.nb_layers - 1):\n",
    "                o = tf.nn.dropout(tf.nn.elu(tf.matmul(W, x) + b), keep_prob = 0.9)\n",
    "            else:\n",
    "                o = tf.nn.softmax(tf.matmul(W, x) + b)\n",
    "                \n",
    "            self.intermediate_outputs.append(o)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CommunicationNet: ## ADD THE MEMORY !! \n",
    "    \n",
    "    def __init__(self, layer_sizes, input_size, first_input, memory, keep_prob = 0.9, memory_size = 32,\n",
    "                 stddev_epsilon = 0.35, output_size = 256, stddev = 0.001):\n",
    "        self.nb_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_size = input_size\n",
    "        self.memory_size = memory_size\n",
    "        self.stddev_epsilon = stddev_epsilon\n",
    "        self.output_size = output_size\n",
    "        self.first_input = first_input\n",
    "        self.stddev = stddev\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.Variable(tf.random_normal([self.layer_sizes[(self.nb_layers-1)], self.memory_size]\n",
    "                                                            ,stddev = self.stddev))\n",
    "        self.intermediate_outputs = [first_input]\n",
    "        self.memory = memory\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.define_inter_outputs()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        for i in range(self.nb_layers):\n",
    "            if i == 0:\n",
    "                W = tf.Variable(tf.random_normal([self.layer_sizes[i], self.input_size], stddev = self.stddev))\n",
    "            elif i != (self.nb_layers - 1):\n",
    "                W = tf.Variable(tf.random_normal([self.layer_sizes[(i+1)], self.layer_sizes[i]],stddev = self.stddev))\n",
    "            else:\n",
    "                W = tf.Variable(tf.random_normal([self.output_size, self.layer_sizes[i]],stddev = self.stddev))\n",
    "            self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        for i in range(self.nb_layers):\n",
    "            B = tf.Variable(tf.random_normal([self.layer_sizes[i], 1],stddev = self.stddev))\n",
    "            self.Biases.append(B)\n",
    "            \n",
    "    def define_inter_outputs(self): ## ADD THE DROPOUTS !!!\n",
    "        for i in range(self.nb_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            x = self.intermediate_outputs[i]\n",
    "            if i != (self.nb_layers - 1):\n",
    "                o = tf.nn.dropout(tf.nn.elu(tf.matmul(W, x) + b), keep_prob = 0.9)\n",
    "            else:\n",
    "                o = tf.nn.softmax(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, self.memory) + b)\n",
    "                \n",
    "            self.intermediate_outputs.append(o)\n",
    "        \n",
    "    def def_delta_mem(self):\n",
    "        self.W_mem = tf.Variable(tf.random_normal(shape =[self.memory_size,self.output_size],stddev = self.stddev))\n",
    "        self.b_mem = tf.Variable(tf.random_normal(shape = [self.memory_size, 1],stddev = self.stddev))\n",
    "        self.output_mem = tf.add(tf.matmul(self.W_mem, self.intermediate_outputs[-1]),self.b_mem)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LastNet: ## ADD THE MEMORY !! The memory initialization is random ==> set it 0\n",
    "    \n",
    "    def __init__(self, layer_sizes, input_size, first_input, memory, keep_prob = 0.9, memory_size = 32, \n",
    "                 stddev_epsilon = 0.35, output_size = 24, stddev = 0.001):\n",
    "        self.nb_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_size = input_size\n",
    "        self.memory_size = memory_size\n",
    "        self.stddev_epsilon = stddev_epsilon\n",
    "        self.output_size = output_size\n",
    "        self.first_input = first_input\n",
    "        self.stddev = stddev\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.Variable(tf.random_normal([self.output_size, self.memory_size],stddev = self.stddev))\n",
    "        self.intermediate_outputs = [self.first_input]\n",
    "        self.memory = memory\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.define_inter_outputs()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        for i in range(self.nb_layers):\n",
    "            if i == 0:\n",
    "                W = tf.Variable(tf.random_normal([self.layer_sizes[i], self.input_size],stddev = self.stddev))\n",
    "            elif i != (self.nb_layers - 1):\n",
    "                W = tf.Variable(tf.random_normal([self.layer_sizes[(i+1)], self.layer_sizes[i]],stddev = self.stddev))\n",
    "            else:\n",
    "                W = tf.Variable(tf.random_normal([self.output_size, self.layer_sizes[i]],stddev = self.stddev))\n",
    "            self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        for i in range(self.nb_layers):\n",
    "            if i != (self.nb_layers - 1):\n",
    "                B = tf.Variable(tf.random_normal([self.layer_sizes[i+1], 1],stddev = self.stddev))\n",
    "            else:\n",
    "                B = tf.Variable(tf.random_normal([self.output_size, 1], stddev = self.stddev))\n",
    "                \n",
    "            self.Biases.append(B)\n",
    "            \n",
    "    def define_inter_outputs(self): ## ADD THE DROPOUTS !!! REMOVE THE SOFTMAX OF THE LAST LAYER !!!\n",
    "        for i in range(self.nb_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            x = self.intermediate_outputs[i]\n",
    "            if i != (self.nb_layers - 1):\n",
    "                o = tf.nn.dropout(tf.nn.elu(tf.matmul(W, x) + b), keep_prob = 0.9)\n",
    "            else:\n",
    "                o = tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, self.memory) + b\n",
    "                \n",
    "            self.intermediate_outputs.append(o)\n",
    "        \n",
    "    def def_delta_mem(self):\n",
    "        self.W_mem = tf.Variable(tf.random_normal(shape =[self.memory_size,self.output_size],stddev = self.stddev))\n",
    "        self.b_mem = tf.Variable(tf.random_normal(shape = [self.memory_size, 1],stddev = self.stddev))\n",
    "        self.output_mem = tf.add(tf.matmul(self.W_mem, self.intermediate_outputs[-1]),self.b_mem)\n",
    "        \n",
    "    def get_output(self):\n",
    "        return self.intermediate_outputs[-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy_Phys:\n",
    "    \n",
    "    def __init__(self, nb_agent, nb_landmark, list_phys_tensors, hidden_layer_size = 256, env_dim = 2, \n",
    "                 batch_size = 1024, stddev_phys_output = 0.01):\n",
    "        self.stddev_phys_output = stddev_phys_output\n",
    "        self.batch_size = batch_size\n",
    "        self.env_dim = env_dim\n",
    "        self.nb_agent = nb_agent\n",
    "        self.nb_landmark = nb_landmark\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.phys_tensors = list_phys_tensors\n",
    "        self.networks_phys = []\n",
    "        self.PhiX = None\n",
    "        \n",
    "        self.init_all()\n",
    "        \n",
    "    def init_phys_modules(self):\n",
    "        with tf.variable_scope(\"physical\") as scope:\n",
    "            self.networks_phys.append(PhysicalNet([self.hidden_layer_size, self.hidden_layer_size], self.env_dim, \n",
    "                                                  self.phys_tensors[0],\n",
    "                                                 self.hidden_layer_size))\n",
    "        for i in range(1, (self.nb_agent + self.nb_landmark)):\n",
    "            with tf.variable_scope(\"physical\", reuse = True):\n",
    "                self.networks_phys.append(PhysicalNet([self.hidden_layer_size, self.hidden_layer_size], self.env_dim,\n",
    "                                                      self.phys_tensors[i],\n",
    "                                                     self.hidden_layer_size))\n",
    "\n",
    "    def init_PhiX(self):\n",
    "        list_outputs = []\n",
    "        for net in self.networks_phys:\n",
    "            list_outputs.append(tf.reshape(net.intermediate_outputs[-1], [256, -1, 1]))\n",
    "\n",
    "        all_phys_output = tf.concat(list_outputs, axis = 2)\n",
    "        self.PhiX = tf.reduce_max(tf.nn.softmax(all_phys_output, dim = -1), axis = 2)\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_phys_modules()\n",
    "        self.init_PhiX()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy_Utterance:\n",
    "    \n",
    "    def __init__(self, nb_agent, list_utter_tensors, list_mem_tensors, goal_size, vocabulary_size = 20, \n",
    "                 hidden_layer_size = 256, memory_size = 32, temperature = 1, batch_size = 1024,\n",
    "                 stddev_phys_output = 0.01):\n",
    "        self.size_goal = goal_size\n",
    "        self.nb_agent = nb_agent\n",
    "        self.stddev_phys_output = stddev_phys_output\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.memory_size = memory_size\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.goal = tf.placeholder(tf.float32, [self.size_goal, None])\n",
    "        self.memory_last = tf.placeholder(tf.float32, [self.memory_size, None])\n",
    "        \n",
    "        self.com_tensors = list_utter_tensors\n",
    "        self.mem_tensors = list_mem_tensors\n",
    "        self.delta_mem = []\n",
    "        self.networks_com = []\n",
    "\n",
    "        self.PhiC = None\n",
    "        self.init_all()\n",
    "        \n",
    "\n",
    "    def init_com_modules(self):## Les poids seront les mêmes pour tous les agents\n",
    "        with tf.variable_scope(\"communication\") as scope:\n",
    "            self.networks_com.append(CommunicationNet([self.hidden_layer_size, self.hidden_layer_size], \n",
    "                                                 self.vocabulary_size, self.com_tensors[0], \n",
    "                                                      self.mem_tensors[0]))\n",
    "        for i in range(1, self.nb_agent):\n",
    "            with tf.variable_scope(\"communication\", reuse=True):\n",
    "                self.networks_com.append(CommunicationNet([self.hidden_layer_size, self.hidden_layer_size], \n",
    "                                                 self.vocabulary_size,self.com_tensors[i],\n",
    "                                                          self.mem_tensors[i]))\n",
    "\n",
    "    def init_delta_mem_tensors(self):\n",
    "        for i in range(self.nb_agent):\n",
    "            self.delta_mem.append(self.networks_com[i].output_mem)\n",
    "            \n",
    "    def init_PhiC(self):\n",
    "        list_outputs = []\n",
    "        for net in self.networks_com:\n",
    "            list_outputs.append(tf.reshape(net.intermediate_outputs[-1], [256, -1, 1]))\n",
    "\n",
    "        all_comm_output = tf.concat(list_outputs, axis = 2)\n",
    "        self.PhiC = tf.reduce_max(tf.nn.softmax(all_comm_output, dim = -1), axis = 2) \n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_com_modules()\n",
    "        self.init_delta_mem_tensors()\n",
    "        self.init_PhiC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy_Last:\n",
    "    \n",
    "    def __init__(self, PhiX, PhiC, goal, memory, hidden_layer_size = 256, \n",
    "                 size_goal = 8, memory_size = 32, batch_size = 1024, stddev_phys_output = 0.01, vocabulary_size = 20,\n",
    "                env_dim = 2, temperature = 1):\n",
    "        self.temperature = temperature\n",
    "        self.stddev_phys_output = stddev_phys_output\n",
    "        self.env_dim = env_dim\n",
    "        self.vocabulary_size = vocabulary_size \n",
    "        self.batch_size = batch_size\n",
    "        self.memory_size = memory_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.size_goal = size_goal\n",
    "        self.goal = goal\n",
    "        self.memory_last = memory\n",
    "        self.Phi = None \n",
    "        self.PhiX = PhiX\n",
    "        self.PhiC = PhiC \n",
    "        self.delta_mem = []\n",
    "        self.init_all()\n",
    "\n",
    "    def init_Phi(self):\n",
    "        self.Phi = tf.concat([self.PhiC, self.goal, self.PhiX], axis = 0)\n",
    "\n",
    "    def init_last_module(self):\n",
    "        inp_size = (2*self.hidden_layer_size + self.size_goal)\n",
    "        out_size = self.vocabulary_size + 2*self.env_dim\n",
    "        self.last_net = LastNet([256, 256], inp_size, self.Phi, self.memory_last, output_size = out_size)\n",
    "        \n",
    "    def init_output(self):\n",
    "        self.output = self.last_net.get_output()\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_Phi()\n",
    "        self.init_last_module()\n",
    "        self.init_output()\n",
    "        self.init_sample_utterances()\n",
    "        self.init_sample_phys()\n",
    "        self.init_delta_mem_tensors()\n",
    "\n",
    "    def init_sample_utterances(self):## Vérifier qu'on prend un bon slice sur l'output\n",
    "        u = -tf.log(-tf.log(tf.random_uniform(shape = [self.vocabulary_size, self.batch_size],dtype=tf.float32)))\n",
    "        utterance_output = tf.slice(self.output, [2*self.env_dim, 0], [self.vocabulary_size, self.batch_size])\n",
    "        gumbel = tf.exp((utterance_output + u)/self.temperature)\n",
    "        denoms = tf.reduce_sum(gumbel, axis = 0)\n",
    "        self.utterance = gumbel/denoms  \n",
    "        \n",
    "    def init_sample_phys(self):\n",
    "        u = tf.random_normal(shape = [2*self.env_dim, self.batch_size],dtype=tf.float32, stddev = self.stddev_phys_output)\n",
    "        self.output = tf.add(tf.slice(self.output, [0, 0], [2*self.env_dim, self.batch_size]), u)\n",
    "        self.sample_move = tf.slice(self.output, [0, 0], [self.env_dim, self.batch_size])\n",
    "        self.sample_gaze  = tf.slice(self.output, [self.env_dim, 0], [self.env_dim, self.batch_size])\n",
    "\n",
    "    def init_delta_mem_tensors(self):\n",
    "        self.delta_mem.append(self.last_net.output_mem)\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy:# Two memories per Agent: one for the communication module, the other one for the last module. Is it correct ?\n",
    "\n",
    "    def __init__(self,nb_agent, nb_landmark, list_phys_tensors, list_utter_tensors, list_mem_tensors, \n",
    "                 list_mem_tensors_last, list_goal_tensors, goal_size, vocabulary_size = 20, hidden_layer_size = 256, \n",
    "                 memory_size = 32, temperature = 1, batch_size = 1024, stddev_phys_output = 0.01, env_dim = 2):\n",
    "        self.nb_agent = nb_agent\n",
    "        self.goal_size = goal_size\n",
    "        self.nb_landmark = nb_landmark\n",
    "        self.list_phys_tensors =  list_phys_tensors\n",
    "        self.list_utter_tensors = list_utter_tensors\n",
    "        self.list_mem_tensors = list_mem_tensors\n",
    "        self.list_goal_tensors = list_goal_tensors\n",
    "        \n",
    "        self.phys_module = Policy_Phys(self.nb_agent, self.nb_landmark, self.list_phys_tensors)\n",
    "        self.utterance_module = Policy_Utterance(self.nb_agent, self.list_utter_tensors, self.list_mem_tensors, \n",
    "                                                 self.goal_size)\n",
    "        \n",
    "        self.list_last_nets = []\n",
    "        self.list_utterance = []\n",
    "        self.list_move = []\n",
    "        self.list_gaze = []\n",
    "        \n",
    "        self.list_delta_mem_comm = self.utterance_module.delta_mem\n",
    "        self.list_delta_mem_last = []\n",
    "        self.list_outputs = []\n",
    "        \n",
    "        self.init_all()\n",
    "        \n",
    "    def init_last_nets(self):### KEEP THE SAME SCOPE IN ORDER TO SHARE THE WEIGHTS !\n",
    "        for i in range(self.nb_agent):\n",
    "            self.list_last_nets.append(Policy_Last(self.phys_module.PhiX, self.utterance_module.PhiC, \n",
    "                                                   self.list_goal_tensors[i], self.list_mem_tensors[i]))\n",
    "            \n",
    "            \n",
    "    def init_output_list(self):\n",
    "        for i in range(self.nb_agent):\n",
    "            self.list_utterance.append(self.list_last_nets[i].utterance)\n",
    "            self.list_move.append(self.list_last_nets[i].sample_move)\n",
    "            self.list_gaze.append(self.list_last_nets[i].sample_gaze)\n",
    "            self.list_delta_mem_last.append(self.list_last_nets[i].delta_mem)\n",
    "            \n",
    "    def init_all(self):\n",
    "        self.init_last_nets()\n",
    "        self.init_output_list()\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, name, name_target, bp, pos, v, gaze, goal_location, goal_type, col,\n",
    "                 vocabulary_size = 20, batch_size = 1024, env_dim = 2, goal_size = 8, \n",
    "                 memory_size = 32, time_delta = 0.1, nb_actions = 3):\n",
    "        self.goal_type = goal_type\n",
    "        self.nb_actions = nb_actions\n",
    "        self.name_target = name_target\n",
    "        self.time_delta = tf.constant([time_delta])\n",
    "        self.env_dim = env_dim\n",
    "        self.memory_size = memory_size\n",
    "        self.name = name\n",
    "        self.goal_size = goal_size\n",
    "        self.batch_size = batch_size\n",
    "        self.bp = bp\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        \n",
    "        self.pos = self.bp.get_past_variable(variable_name = \"pos_\" + str(self.name), starting_value = np.float32(pos)) \n",
    "        self.velocity = self.bp.get_past_variable(\"velocity_\" + str(self.name), np.float32(v)) \n",
    "        self.gaze = self.bp.get_past_variable(\"gaze_\" + str(self.name), np.float32(gaze))\n",
    "        self.utterance = self.bp.get_past_variable(\"utterance_\" + str(self.name), \n",
    "                                                   np.float32(np.zeros([self.vocabulary_size, self.batch_size])))\n",
    "        \n",
    "        self.memory = self.bp.get_past_variable(\"memory_\" + str(self.name), np.float32(np.zeros([self.memory_size, \n",
    "                                                                                         self.batch_size])))\n",
    "        \n",
    "        self.memory_last = self.bp.get_past_variable(\"memory_last_\" + str(self.name), np.float32(\n",
    "            np.zeros([self.memory_size, self.batch_size])))\n",
    "        \n",
    "        self.tensor_goal_location = tf.constant(goal_location, tf.float32)\n",
    "        self.tensor_goal_type = tf.constant(goal_type, tf.float32)\n",
    "        self.col = tf.constant(col, tf.float32)\n",
    "        \n",
    "    def take_step(self, list_positions, list_utterances, list_mem_comm, list_deltamem_comm, list_mem_last,\n",
    "              list_detlamem_last, goal, session):\n",
    "        feed_dict_all = self.create_feed_dict(list_positions, list_utterances, list_mem_comm, list_deltamem_comm, \n",
    "                list_mem_last, list_detlamem_last, goal)\n",
    "        return session.run([self.utterances, self.sample_move], feed_dict = feed_dict_all) \n",
    "\n",
    "    def get_move(self):\n",
    "        return self.p.sample_move\n",
    "    \n",
    "    def get_utterance(self):\n",
    "        return self.p.utterance\n",
    "    \n",
    "    def compute_reward_agent(self,tensor_agent_pos, tensor_agent_gaze):\n",
    "        ### Il faut prendre la position pour le goal et non pas l'agent spécifique.\n",
    "        r1 = tf.reshape(tf.square(tf.norm(tensor_agent_pos - self.tensor_goal_location, axis = 0)), [1, self.batch_size])\n",
    "        r2 = tf.reshape(tf.square(tf.norm(tensor_agent_gaze - self.tensor_goal_location, axis = 0)), [1, self.batch_size])\n",
    "        utt_norm = tf.square(tf.norm(self.new_utterance, axis = 0))\n",
    "        u_norm = tf.square(tf.norm(tf.concat([self.new_pos, self.new_gaze], axis = 0), axis = 0))\n",
    "        vec = tf.concat([r1, r2, tf.zeros([1,self.batch_size], tf.float32)], axis = 0)\n",
    "        v1 = tf.reduce_sum(tf.multiply(vec, self.tensor_goal_type), axis = 0)\n",
    "        r = -(v1 + utt_norm + u_norm)\n",
    "        return r\n",
    "            \n",
    "    def compute_new_state(self, tensor_utterance, tensor_velocity, tensor_gaze, tensor_memory_delta, \n",
    "                          tensor_memory_last):\n",
    "        ## ADD THE FORCES TO THE NEW VELOCITY !!\n",
    "        ## Find \"uv\", the new gaze location...\n",
    "        ## ADD GAUSSIAN NOISE TO THE MEMORY UPDATE !\n",
    "        self.new_pos = self.bp.name_variable(variable_name = \"pos_\" + str(self.name), \n",
    "                                        v = self.pos + tf.multiply(self.velocity,self.time_delta))\n",
    "        self.new_velocity = self.bp.name_variable(\"velocity_\" + str(self.name), \n",
    "                                        self.velocity + tf.multiply(tensor_velocity, self.time_delta))\n",
    "        self.new_gaze = self.bp.name_variable(\"gaze_\" + str(self.name), tensor_gaze)\n",
    "        self.new_memory = self.bp.name_variable(\"memory_\" + str(self.name), self.memory + tensor_memory_delta)\n",
    "        self.new_memory_last = self.bp.name_variable(\"memory_last_\" + str(self.name), self.memory_last + tensor_memory_last)\n",
    "        self.new_utterance = self.bp.name_variable(\"utterance_\" + str(self.name), tensor_utterance)\n",
    "\n",
    "                                            \n",
    "    def get_position(self):\n",
    "        return self.pos\n",
    "    \n",
    "    def get_velocity(self):\n",
    "        return self.velocity\n",
    "    \n",
    "    def get_gaze(self):\n",
    "        return self.gaze\n",
    "\n",
    "    def get_utterance(self):\n",
    "        return self.utterance\n",
    "                                        \n",
    "    def get_memory(self):\n",
    "        return self.memory\n",
    "    \n",
    "    def get_memory_last(self):\n",
    "        return self.memory_last\n",
    "    \n",
    "    def get_phys_state(self):\n",
    "        return (self.get_position(), self.get_velocity(), self.get_gaze(), self.get_col)\n",
    "    \n",
    "    def get_name_target(self):\n",
    "        return self.name_target\n",
    "    \n",
    "    def get_goal(self, other_ags):\n",
    "        other_agents = [other_ags[i].get_color() for i in self.name_target[0, :]]\n",
    "        colors = tf.concat(other_agents, axis = 1)\n",
    "        return tf.concat([self.tensor_goal_type, self.tensor_goal_location, colors], axis = 0)\n",
    "          \n",
    "    def get_all_iterations_variables(self):\n",
    "        return self.pos, self.velocity, self.gaze, self.utterance, self.memory, self.memory_last\n",
    "    \n",
    "    def get_color(self):\n",
    "        return self.col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    # Use this class to instantiate an environment on N batches. All batches share the same structure, but not not the\n",
    "    # same goals.\n",
    "    def __init__(self, bp, nb_agents = 3, nb_landmarks = 0, env_dim = 2, batch_size = 1024, goal_type_size = 3):\n",
    "        self.env_dim = env_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.goal_type_size = goal_type_size\n",
    "        self.goal_size = self.goal_type_size + 3 + self.env_dim\n",
    "        self.nb_agents = nb_agents\n",
    "        self.nb_landmarks = nb_landmarks\n",
    "        self.list_agents = []\n",
    "        self.list_phys_tensors = []\n",
    "        self.list_utter_tensors = []\n",
    "        self.list_mem_tensors = []\n",
    "        self.list_mem_last_tensors = []\n",
    "        self.list_goals_tensors = []\n",
    "        self.bp = bp\n",
    "        \n",
    "    def init_agents(self):\n",
    "        for i in range(self.nb_agents):\n",
    "            name_of_targets = np.random.randint(0, self.nb_agents, (1, self.batch_size))\n",
    "            p = np.zeros([self.env_dim, self.batch_size])\n",
    "            v = np.zeros([self.env_dim, self.batch_size])\n",
    "            g = np.zeros([self.env_dim, self.batch_size])\n",
    "            go = np.zeros([self.goal_type_size, self.batch_size])\n",
    "            co = np.random.uniform(0, 255, [3, 1])\n",
    "            ag = Agent(name = i, name_target = name_of_targets, bp = self.bp, \n",
    "                       pos = p, v = v, gaze = g, goal_location = p, goal_type = go, col = co)\n",
    "            self.list_agents.append(ag)\n",
    "            self.list_phys_tensors.append(ag.get_position())\n",
    "            self.list_utter_tensors.append(ag.get_utterance())\n",
    "            self.list_mem_tensors.append(ag.get_memory())\n",
    "            self.list_mem_last_tensors.append(ag.get_memory_last())\n",
    "            \n",
    "    def init_goals_tensors(self):\n",
    "        for ag in self.list_agents: \n",
    "            self.list_goals_tensors.append(ag.get_goal(self.list_agents))\n",
    "     \n",
    "    def init_policy(self):\n",
    "        self.policy = Policy(self.nb_agents, self.nb_landmarks, self.list_phys_tensors, self.list_utter_tensors, \n",
    "                            self.list_mem_tensors, self.list_mem_last_tensors, self.list_goals_tensors, self.goal_size)\n",
    "        \n",
    "    def init_new_agents_states(self):\n",
    "        for i in range(self.nb_agents):\n",
    "            ag = self.list_agents[i]\n",
    "            tens_utterance = self.policy.list_utterance[i]\n",
    "            tens_velocity = self.policy.list_move[i]\n",
    "            tens_gaze = self.policy.list_gaze[i]\n",
    "            tens_mem_delta = self.policy.list_delta_mem_comm[i]\n",
    "            tens_mem_delta_last = self.policy.list_delta_mem_last[i]\n",
    "            ag.compute_new_state(tens_utterance, tens_velocity, tens_gaze, tens_mem_delta, tens_mem_delta_last)\n",
    "         \n",
    "\n",
    "    def init_reward_agents(self): ## Check the shuffle for the pos of agent and gaze is OK !!\n",
    "        rewards = []\n",
    "        ag_positions = []\n",
    "        ag_gazes = []\n",
    "        ag_goal_on_agent = []\n",
    "        for agent in self.list_agents:\n",
    "            ag_positions.append(agent.get_position())\n",
    "            ag_gazes.append(agent.get_gaze())\n",
    "            \n",
    "        agent_positions = tf.stack(ag_positions, axis = 2)\n",
    "        agent_gazes = tf.stack(ag_gazes, axis = 2)\n",
    "        \n",
    "        for i in range(self.nb_agents):\n",
    "            rewards = []\n",
    "            agent = self.list_agents[i]\n",
    "            name_target = agent.get_name_target()\n",
    "            position_target = tf.reshape(tf.slice(agent_positions, [0, 0, i], [self.env_dim, self.batch_size, 1]), \n",
    "                                         [self.env_dim, self.batch_size])\n",
    "            \n",
    "            gaze_target = tf.reshape(tf.slice(agent_gazes, [0, 0, i], [self.env_dim, self.batch_size, 1]), \n",
    "                                         [self.env_dim, self.batch_size])\n",
    "            \n",
    "            reward_agent = agent.compute_reward_agent(position_target, gaze_target)\n",
    "            rewards.append(reward_agent)\n",
    "            \n",
    "            self.rewards_batch = tf.reduce_sum(tf.concat(rewards, axis = 0), axis = 0)\n",
    "                     \n",
    "    def init_all(self):\n",
    "        self.init_agents()\n",
    "        self.init_goals_tensors()\n",
    "        self.init_policy()\n",
    "        self.init_new_agents_states()\n",
    "        self.init_reward_agents()\n",
    "        \n",
    "    def init_graph(self):\n",
    "        self.init_all()\n",
    "        \n",
    "    def get_all_iteration_var(self):\n",
    "        return [tensor for ag in self.list_agents for tensor in ag.get_all_iterations_variables()]\n",
    "    \n",
    "    def get_reward_batch(self):\n",
    "        return self.rewards_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self, time_horizon):\n",
    "        self.bp = BPTT()\n",
    "        self.time_horizon = time_horizon\n",
    "        tf.reset_default_graph()\n",
    "            \n",
    "    def instantiate_graph(self, bp, depth_type):## ADD THE AUXILIARY REWARDS !!!!!\n",
    "        env = Environment(self.bp)\n",
    "        env.init_all()\n",
    "        return [env.get_reward_batch()]\n",
    "    \n",
    "    def instantiate_both_graphs(self):\n",
    "        self.graphs = self.bp.generate_graphs(self.instantiate_graph, self.time_horizon)\n",
    "        \n",
    "    def train_batch(self, sess):\n",
    "        loss = tf.reduce_mean(self.graphs[\"deep\"])\n",
    "        print(\"Initializing\")\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "        print(\"Creating dict\")\n",
    "        frame_dict = self.bp.generate_feed_dict(\"deep\", [], 0)\n",
    "        print(\"Start running\")\n",
    "        l = sess.run(loss, feed_dict = frame_dict)\n",
    "        return l\n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp = Experiment(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp.instantiate_both_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n",
      "Creating dict\n",
      "Start running\n",
      "-262.445\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(exp.train_batch(sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = exp.graphs[\"deep\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_1:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor 'unrolled_model/unroll/Sum_8:0' shape=() dtype=float32>],\n",
       " [<tf.Tensor 'unrolled_model/unroll_1/Sum_8:0' shape=() dtype=float32>],\n",
       " [<tf.Tensor 'unrolled_model/unroll_2/Sum_8:0' shape=() dtype=float32>],\n",
       " [<tf.Tensor 'unrolled_model/unroll_3/Sum_8:0' shape=() dtype=float32>]]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros([2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = np.array([[1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
